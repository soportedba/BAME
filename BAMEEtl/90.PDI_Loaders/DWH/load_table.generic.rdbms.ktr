<?xml version="1.0" encoding="UTF-8"?>
<transformation>
  <info>
    <name>load_table.generic.rdbms</name>
    <description />
    <extended_description />
    <trans_version />
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>/</directory>
    <parameters>
    </parameters>
    <log>
      <trans-log-table>
        <connection />
        <schema />
        <table />
        <size_limit_lines />
        <interval />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STATUS</id>
          <enabled>Y</enabled>
          <name>STATUS</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
          <subject />
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
          <subject />
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
          <subject />
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
          <subject />
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
          <subject />
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
          <subject />
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>STARTDATE</id>
          <enabled>Y</enabled>
          <name>STARTDATE</name>
        </field>
        <field>
          <id>ENDDATE</id>
          <enabled>Y</enabled>
          <name>ENDDATE</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>DEPDATE</id>
          <enabled>Y</enabled>
          <name>DEPDATE</name>
        </field>
        <field>
          <id>REPLAYDATE</id>
          <enabled>Y</enabled>
          <name>REPLAYDATE</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>Y</enabled>
          <name>LOG_FIELD</name>
        </field>
        <field>
          <id>EXECUTING_SERVER</id>
          <enabled>N</enabled>
          <name>EXECUTING_SERVER</name>
        </field>
        <field>
          <id>EXECUTING_USER</id>
          <enabled>N</enabled>
          <name>EXECUTING_USER</name>
        </field>
        <field>
          <id>CLIENT</id>
          <enabled>N</enabled>
          <name>CLIENT</name>
        </field>
      </trans-log-table>
      <perf-log-table>
        <connection />
        <schema />
        <table />
        <interval />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>SEQ_NR</id>
          <enabled>Y</enabled>
          <name>SEQ_NR</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>INPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>INPUT_BUFFER_ROWS</name>
        </field>
        <field>
          <id>OUTPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>OUTPUT_BUFFER_ROWS</name>
        </field>
      </perf-log-table>
      <channel-log-table>
        <connection />
        <schema />
        <table />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>LOGGING_OBJECT_TYPE</id>
          <enabled>Y</enabled>
          <name>LOGGING_OBJECT_TYPE</name>
        </field>
        <field>
          <id>OBJECT_NAME</id>
          <enabled>Y</enabled>
          <name>OBJECT_NAME</name>
        </field>
        <field>
          <id>OBJECT_COPY</id>
          <enabled>Y</enabled>
          <name>OBJECT_COPY</name>
        </field>
        <field>
          <id>REPOSITORY_DIRECTORY</id>
          <enabled>Y</enabled>
          <name>REPOSITORY_DIRECTORY</name>
        </field>
        <field>
          <id>FILENAME</id>
          <enabled>Y</enabled>
          <name>FILENAME</name>
        </field>
        <field>
          <id>OBJECT_ID</id>
          <enabled>Y</enabled>
          <name>OBJECT_ID</name>
        </field>
        <field>
          <id>OBJECT_REVISION</id>
          <enabled>Y</enabled>
          <name>OBJECT_REVISION</name>
        </field>
        <field>
          <id>PARENT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>PARENT_CHANNEL_ID</name>
        </field>
        <field>
          <id>ROOT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>ROOT_CHANNEL_ID</name>
        </field>
      </channel-log-table>
      <step-log-table>
        <connection />
        <schema />
        <table />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>N</enabled>
          <name>LOG_FIELD</name>
        </field>
      </step-log-table>
      <metrics-log-table>
        <connection />
        <schema />
        <table />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>METRICS_DATE</id>
          <enabled>Y</enabled>
          <name>METRICS_DATE</name>
        </field>
        <field>
          <id>METRICS_CODE</id>
          <enabled>Y</enabled>
          <name>METRICS_CODE</name>
        </field>
        <field>
          <id>METRICS_DESCRIPTION</id>
          <enabled>Y</enabled>
          <name>METRICS_DESCRIPTION</name>
        </field>
        <field>
          <id>METRICS_SUBJECT</id>
          <enabled>Y</enabled>
          <name>METRICS_SUBJECT</name>
        </field>
        <field>
          <id>METRICS_TYPE</id>
          <enabled>Y</enabled>
          <name>METRICS_TYPE</name>
        </field>
        <field>
          <id>METRICS_VALUE</id>
          <enabled>Y</enabled>
          <name>METRICS_VALUE</name>
        </field>
      </metrics-log-table>
    </log>
    <maxdate>
      <connection />
      <table />
      <field />
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>8000000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>1000000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file />
    <capture_step_performance>N</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
      <slaveserver>
        <name>etl_master</name>
        <hostname>etlmaster</hostname>
        <port>20400</port>
        <webAppName />
        <username>cluster</username>
        <password>Encrypted 2be98afc86aa7f2e4cb1aa265cd86aac8</password>
        <proxy_hostname />
        <proxy_port />
        <non_proxy_hosts />
        <master>Y</master>
        <sslMode>N</sslMode>
      </slaveserver>
      <slaveserver>
        <name>etlmaster</name>
        <hostname>etlmaster</hostname>
        <port>20400</port>
        <webAppName />
        <username>cluster</username>
        <password>Encrypted 2be98afc86aa7f2e4cb1aa265cd86aac8</password>
        <proxy_hostname />
        <proxy_port />
        <non_proxy_hosts />
        <master>Y</master>
        <sslMode>N</sslMode>
      </slaveserver>
    </slaveservers>
    <clusterschemas>
      <clusterschema>
        <name>ETL_CSIC</name>
        <base_port>99999</base_port>
        <sockets_buffer_size>2000</sockets_buffer_size>
        <sockets_flush_interval>5000</sockets_flush_interval>
        <sockets_compressed>Y</sockets_compressed>
        <dynamic>Y</dynamic>
        <slaveservers>
          <name>etl_master</name>
        </slaveservers>
      </clusterschema>
    </clusterschemas>
    <created_user>-</created_user>
    <created_date>2013/10/18 20:30:57.177</created_date>
    <modified_user>-</modified_user>
    <modified_date>2013/10/18 20:30:57.177</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA=</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
  </notepads>
  <connection>
    <name>BAME</name>
    <server>${IP_BAME}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${DATABASE_BAME}</database>
    <port>${PORT_BAME}</port>
    <username>${USER_BAME}</username>
    <password>${PASSWORD_BAME}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${PORT_BAME}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <order>
    <hop>
      <from>Mappings</from>
      <to>Conversions</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Mappings</from>
      <to>RowValidationError</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>generateConnectionData</from>
      <to>Search_table</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>generateConnectionData</from>
      <to>load_table.generic.rdbms.log.1</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Search_table</from>
      <to>load_table.generic.rdbms.log.2</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Mappings</from>
      <to>load_table.generic.rdbms.log.3</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Conversions</from>
      <to>Dummy (do nothing)</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Dummy (do nothing)</from>
      <to>write_sta_table</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Search_table</from>
      <to>Mappings</to>
      <enabled>Y</enabled>
    </hop>
  </order>
  <step>
    <name>Conversions</name>
    <type>SelectValues</type>
    <description />
    <distribute>N</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <select_unspecified>Y</select_unspecified>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>464</xloc>
      <yloc>112</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Dummy (do nothing)</name>
    <type>Dummy</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>720</xloc>
      <yloc>112</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Mappings</name>
    <type>JsonInput</type>
    <description />
    <distribute>N</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <include>N</include>
    <include_field />
    <rownum>N</rownum>
    <addresultfile>N</addresultfile>
    <readurl>N</readurl>
    <removeSourceField>N</removeSourceField>
    <IsIgnoreEmptyFile>N</IsIgnoreEmptyFile>
    <doNotFailIfNoFile>Y</doNotFailIfNoFile>
    <ignoreMissingPath>Y</ignoreMissingPath>
    <rownum_field />
    <file>
      <name />
      <filemask />
      <exclude_filemask />
      <file_required>N</file_required>
      <include_subfolders>N</include_subfolders>
    </file>
    <fields>
    </fields>
    <limit>0</limit>
    <IsInFields>Y</IsInFields>
    <IsAFile>N</IsAFile>
    <valueField>json_collection</valueField>
    <shortFileFieldName />
    <pathFieldName />
    <hiddenFieldName />
    <lastModificationTimeFieldName />
    <uriNameFieldName />
    <rootUriNameFieldName />
    <extensionFieldName />
    <sizeFieldName />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>320</xloc>
      <yloc>112</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>RowValidationError</name>
    <type>WriteToLog</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <loglevel>log_level_basic</loglevel>
    <displayHeader>Y</displayHeader>
    <limitRows>N</limitRows>
    <limitRowsNumber>0</limitRowsNumber>
    <logmessage>Row Validation error</logmessage>
    <fields>
      <field>
        <name>json_collection</name>
      </field>
      <field>
        <name>fec_ini_iso</name>
      </field>
      <field>
        <name>fec_fin_iso</name>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>464</xloc>
      <yloc>208</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Search_table</name>
    <type>UserDefinedJavaClass</type>
    <description />
    <distribute>N</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <definitions>
      <definition>
        <class_type>TRANSFORM_CLASS</class_type>
        <class_name>Processor</class_name>
        <class_source>import  org.pentaho.di.core.database.*;
import  java.sql.*;
import  org.json.simple.JSONObject;
import org.json.simple.parser.JSONParser;
private Connection conn;

public boolean processRow(StepMetaInterface smi, StepDataInterface sdi) throws KettleException
{
  Object[] r=getRow();
  if (r==null)
  {
    setOutputDone();
	return false;
  }
	// Querys my change by provider
	String provider= get(Fields.In, "provider").getString(r);
	String database= get(Fields.In, "database").getString(r);
	String ipport= get(Fields.In, "ipport").getString(r);
	String username= get(Fields.In, "username").getString(r);
	String password= get(Fields.In, "password").getString(r);
	try {

		String databaseUri = "";

		if (provider.equals("org.postgresql.Driver")) {
			databaseUri = "jdbc:postgresql://"+ipport+"/"+database;
		}else if(provider.equals("com.microsoft.sqlserver.jdbc.SQLServerDriver")){
			databaseUri = "jdbc:sqlserver://"+ipport+";databaseName="+database+";integratedSecurity=false";
		}else if(provider.equals("org.gjt.mm.mysql.Driver")){
			databaseUri = "jdbc:mysql://"+ipport+"/"+database+"?useSSL=false";
		}else if(provider.equals("oracle.jdbc.driver.OracleDriver")){
			databaseUri = "jdbc:oracle:thin:@"+ipport+":"+database;
		}else{
			logBasic("Error with database provider: "+provider);
			return false;
		}

		Class.forName(provider);
		conn = DriverManager.getConnection(databaseUri, username, password);

	} catch(Exception e) {
	  	logError("Error connecting to Database "+provider+" - "+database, e);
    		return false;
	}

	Integer f_skip=((Long) get(Fields.In, "f_skip").getInteger(r)).intValue();
	Integer f_limit=((Long) get(Fields.In, "f_limit").getInteger(r)).intValue();
	String source_timestamp_column = get(Fields.In, "source_timestamp_column").getString(r);
	String FEC_INI_ISO = get(Fields.In, "FEC_INI_ISO").getString(r);
	String FEC_FIN_ISO = get(Fields.In, "FEC_FIN_ISO").getString(r);
	String dmlquery = get(Fields.In, "dmlquery").getString(r);
	
	//logBasic("f_skip,f_limit,source_timestamp_column,fec_ini_iso,fec_fin_iso,dmlquery: "+f_skip+","+f_limit+","+source_timestamp_column+","+FEC_INI_ISO+","+FEC_FIN_ISO+","+dmlquery);
	
	Statement stmt = null;    
	Object[] outputRow = createOutputRow(new Object[0], data.outputRowMeta.size());
	JSONObject obj = new JSONObject();
	JSONObject obj1= new JSONObject();		
	String rstmp="";
	String column_name="";
	Integer column_type=0;
	
	try {
	stmt = conn.createStatement();

	String sql = "";
	
	if (provider.equals("org.postgresql.Driver")) {
		if (FEC_INI_ISO.equals("1900-01-01T00:00:00.000Z") &amp;&amp; FEC_FIN_ISO.equals("2200-01-01T00:00:00.000Z")) {
			sql = "select * from "+dmlquery+" x order by \""+source_timestamp_column+"\" limit "+f_limit+" offset "+f_skip;
		}else{
			sql = "select * from "+dmlquery+" x where \""+source_timestamp_column+"\" between '"+FEC_INI_ISO+"' and '"+FEC_FIN_ISO+"' order by \""+source_timestamp_column+"\" limit "+f_limit+" offset "+f_skip;
		}
	}else if(provider.equals("com.microsoft.sqlserver.jdbc.SQLServerDriver")){
		if (FEC_INI_ISO.equals("1900-01-01T00:00:00.000Z") &amp;&amp; FEC_FIN_ISO.equals("2200-01-01T00:00:00.000Z")) {
			sql = "select * from "+dmlquery+" x order by \""+source_timestamp_column+"\" OFFSET "+f_skip+" ROWS FETCH NEXT "+f_limit+" ROWS ONLY";
		}else{
			sql = "select * from "+dmlquery+" x where \""+source_timestamp_column+"\" between '"+FEC_INI_ISO+"' and '"+FEC_FIN_ISO+"' order by \""+source_timestamp_column+"\" OFFSET "+f_skip+" ROWS FETCH NEXT "+f_limit+" ROWS ONLY";
		}
	}else if(provider.equals("org.gjt.mm.mysql.Driver")){
		// NON quoted fields
		if (FEC_INI_ISO.equals("1900-01-01T00:00:00.000Z") &amp;&amp; FEC_FIN_ISO.equals("2200-01-01T00:00:00.000Z")) {
			sql = "select * from "+dmlquery+" x order by "+source_timestamp_column+" LIMIT "+f_skip+","+f_limit;
		}else{
			sql = "select * from "+dmlquery+" x where "+source_timestamp_column+" between str_to_date('"+FEC_INI_ISO+"','%Y-%m-%dT%H:%i:%s.%fZ') and str_to_date('"+FEC_FIN_ISO+"','%Y-%m-%dT%H:%i:%s.%fZ') order by "+source_timestamp_column+" LIMIT "+f_skip+","+f_limit;
		}	
	}else if(provider.equals("oracle.jdbc.driver.OracleDriver")){
		if (FEC_INI_ISO.equals("1900-01-01T00:00:00.000Z") &amp;&amp; FEC_FIN_ISO.equals("2200-01-01T00:00:00.000Z")) {
			sql = "select * from (select rownum rnum, a.* from (select * from "+dmlquery+" x order by \""+source_timestamp_column+"\") a where rownum &lt;= "+f_skip+"+"+f_limit+") where rnum >= "+f_skip;
		}else{
			sql = "select * from (select rownum rnum, a.* from (select * from "+dmlquery+" x where \""+source_timestamp_column+"\" between TO_TIMESTAMP('"+FEC_INI_ISO+"','YYYY-MM-DD\"T\"HH24:MI:SS.FF3\"Z\"') and TO_TIMESTAMP('"+FEC_FIN_ISO+"','YYYY-MM-DD\"T\"HH24:MI:SS.FF3\"Z\"') order by \""+source_timestamp_column+"\") a where rownum &lt;= "+f_skip+"+"+f_limit+") where rnum >= "+f_skip;
		}	
	}else{
		logBasic("Error with database generated query for provider: "+provider+" - "+sql);
		return false;
	}
	//logBasic("SQL generated query for provider: "+provider+" - "+sql);
	
	ResultSet rs = stmt.executeQuery(sql);

	//JSONArray json = new JSONArray();
    ResultSetMetaData rsmd = rs.getMetaData();
    int numColumns = rsmd.getColumnCount();
	while(rs.next()) {
	  //Object obj = parser.parse(new FileReader("f:\\test.json"));
	  obj = new JSONObject();
	  obj1= new JSONObject();
	  //rstmp=rs.getString("value");
	  JSONParser parser = new JSONParser();

	  for( int i=1; i&lt;numColumns+1; i++) {
		column_name = rsmd.getColumnName(i);
		column_type = rsmd.getColumnType(i);
		switch( rsmd.getColumnType( i ) ) {
		  case java.sql.Types.ARRAY:
			obj.put(column_name, rs.getArray(column_name));     break;
		  case java.sql.Types.BIGINT:
			obj.put(column_name, rs.getInt(column_name));       break;
		  case java.sql.Types.BOOLEAN:
			obj.put(column_name, rs.getBoolean(column_name));   break;
		  case java.sql.Types.BLOB:
			obj.put(column_name, rs.getBlob(column_name));      break;
		  case java.sql.Types.DOUBLE:
			obj.put(column_name, rs.getDouble(column_name));    break;
		  case java.sql.Types.FLOAT:
			obj.put(column_name, rs.getFloat(column_name));     break;
		  case java.sql.Types.INTEGER:
			obj.put(column_name, rs.getInt(column_name));       break;
		  case java.sql.Types.NVARCHAR:
			obj.put(column_name, rs.getNString(column_name));   break;
		  case java.sql.Types.VARCHAR:
			obj.put(column_name, rs.getString(column_name));    break;
		  case java.sql.Types.TINYINT:
			obj.put(column_name, rs.getInt(column_name));       break;
		  case java.sql.Types.SMALLINT:
			obj.put(column_name, rs.getInt(column_name));       break;
		  case java.sql.Types.DATE:
			obj.put(column_name, rs.getDate(column_name));      break;
		  case java.sql.Types.TIMESTAMP:
			obj.put(column_name, rs.getTimestamp(column_name)); break;
		  default:
			// When type is undefined (Object, Text, ...) its asumed to be a json object to be used to extract field later
			obj1=(JSONObject) parser.parse(rs.getString(column_name));
			obj.put(column_name, obj1); break;
		}
	  }
		rstmp=obj.toString();
		get(Fields.Out, "json_collection").setValue(outputRow, rstmp);
		get(Fields.Out, "fec_ini_iso").setValue(outputRow, FEC_INI_ISO);
		get(Fields.Out, "fec_fin_iso").setValue(outputRow, FEC_FIN_ISO);
		putRow(data.outputRowMeta, outputRow);
	}
}
catch(Exception e){
	//Handle errors for Class.forName
	logBasic("Error Exception rs:"+rstmp);
	logBasic("Error Exception obj:"+obj.toString());
	logBasic("Error Exception column_name:"+column_name);
	logBasic("Error Exception column_type:"+column_type);
	//System.err.println("In catch Exception: "+e.getClass());
	e.printStackTrace();    
	//Alert("yo");
	putError(getInputRowMeta(), outputRow, 1, e.toString()+" - LINE - "+obj.toString(), "", "");
	}
finally{
	 //finally block used to close resources
	 try{
		if(stmt!=null)
		   conn.close();
	 }catch(SQLException se){
		se.printStackTrace(); 
	 }// do nothing
	 try{
		if(conn!=null)
		   conn.close();
	 }catch(SQLException se){
		se.printStackTrace();
	 }
	//end finally try    
	}  
	 return true;
}

public boolean init(StepMetaInterface stepMetaInterface, StepDataInterface stepDataInterface)
{
	return parent.initImpl(stepMetaInterface, stepDataInterface);
}

public void dispose(StepMetaInterface smi, StepDataInterface sdi)
{
    if (conn != null) {
		try{
        conn.close();
		} catch(SQLException se){
	 }// do nothing
	 try{
		if(conn!=null)
		   conn.close();
	 }catch(SQLException se){
		se.printStackTrace();
	 }
    }
 
    parent.disposeImpl(smi, sdi);
}

</class_source>
      </definition>
    </definitions>
    <fields>
      <field>
        <field_name>json_collection</field_name>
        <field_type>String</field_type>
        <field_length>-1</field_length>
        <field_precision>-1</field_precision>
      </field>
      <field>
        <field_name>fec_ini_iso</field_name>
        <field_type>String</field_type>
        <field_length>-1</field_length>
        <field_precision>-1</field_precision>
      </field>
      <field>
        <field_name>fec_fin_iso</field_name>
        <field_type>String</field_type>
        <field_length>-1</field_length>
        <field_precision>-1</field_precision>
      </field>
    </fields>
    <clear_result_fields>Y</clear_result_fields>
    <info_steps />
    <target_steps />
    <usage_parameters />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>160</xloc>
      <yloc>112</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>generateConnectionData</name>
    <type>DataGrid</type>
    <description />
    <distribute>N</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
    </fields>
    <data>
      <line>  </line>
    </data>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>64</xloc>
      <yloc>112</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>load_table.generic.rdbms.log.1</name>
    <type>WriteToLog</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <loglevel>log_level_debug</loglevel>
    <displayHeader>Y</displayHeader>
    <limitRows>N</limitRows>
    <limitRowsNumber>0</limitRowsNumber>
    <logmessage />
    <fields>
      </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>64</xloc>
      <yloc>208</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>load_table.generic.rdbms.log.2</name>
    <type>WriteToLog</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <loglevel>log_level_debug</loglevel>
    <displayHeader>Y</displayHeader>
    <limitRows>N</limitRows>
    <limitRowsNumber>0</limitRowsNumber>
    <logmessage />
    <fields>
      </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>272</xloc>
      <yloc>208</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>load_table.generic.rdbms.log.3</name>
    <type>WriteToLog</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <loglevel>log_level_debug</loglevel>
    <displayHeader>Y</displayHeader>
    <limitRows>N</limitRows>
    <limitRowsNumber>0</limitRowsNumber>
    <logmessage />
    <fields>
      </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>656</xloc>
      <yloc>208</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>write_sta_table</name>
    <type>TableOutput</type>
    <description />
    <distribute>N</distribute>
    <custom_distribution />
    <copies>${COPIES_WRITE}</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>BAME</connection>
    <schema />
    <table />
    <commit>1000</commit>
    <truncate>N</truncate>
    <ignore_errors>N</ignore_errors>
    <use_batch>Y</use_batch>
    <specify_fields>Y</specify_fields>
    <partitioning_enabled>N</partitioning_enabled>
    <partitioning_field />
    <partitioning_daily>N</partitioning_daily>
    <partitioning_monthly>Y</partitioning_monthly>
    <tablename_in_field>N</tablename_in_field>
    <tablename_field />
    <tablename_in_table>N</tablename_in_table>
    <return_keys>N</return_keys>
    <return_field />
    <fields>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>912</xloc>
      <yloc>112</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step_error_handling>
    <error>
      <source_step>Mappings</source_step>
      <target_step>RowValidationError</target_step>
      <is_enabled>Y</is_enabled>
      <nr_valuename />
      <descriptions_valuename />
      <fields_valuename />
      <codes_valuename />
      <max_errors />
      <max_pct_errors />
      <min_pct_rows />
    </error>
  </step_error_handling>
  <slave-step-copy-partition-distribution>
  </slave-step-copy-partition-distribution>
  <slave_transformation>N</slave_transformation>
</transformation>
